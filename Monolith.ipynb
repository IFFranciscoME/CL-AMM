{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMz9sFRnui1e5OMgjStgJ3A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IFFranciscoME/CL-AMM/blob/main/Monolith.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Brief Vision\n",
        "---"
      ],
      "metadata": {
        "id": "9I0muLryJwwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The requested/suggested perspective and evaluation criteria for this task had these 3 areas of focus:\n",
        "\n",
        "1. Reasoning\n",
        "2. Engineering decisions\n",
        "3. Priorities\n",
        "\n",
        "Which I re-interpreted as the following type of activities:\n",
        "\n",
        "1. Modeling Financial Process.\n",
        "2. Data Architecture & Systems Design.\n",
        "3. Product Management / Project Management.\n",
        "\n",
        "## Update general knowledge\n",
        "\n",
        "Update knowledge about Liquidity Provision in Automated Market Makers OnChain with Concentrated Liquidity Architecture.\n",
        "\n",
        "References:\n",
        "\n",
        "- Docs for **EKUBO**: https://docs.ekubo.org/ | https://uniswapv3book.com/\n",
        "- Docs for **Uniswap V3**: https://docs.uniswap.org/contracts/v3/overview\n",
        "- **Fritsch, Robin.** Concentrated Liquidity in Automated Market Makers. Proceedings of the 2021 ACM CCS workshop on decentralized finance and security. 2021.\n",
        "\n",
        "## Fundamental Abstract Components\n",
        "\n",
        "Define what would be the fundamental elements for a for-profit liquidity provision strategy for CL-AMM\n",
        "\n",
        "- Anchor Price: A single value, decision: How to choose it.\n",
        "- Price Range: A tuple of 2 values, decision: Which Unit of definition to use, Which magnitud will it have, is it symmetric in both directions,\n",
        "- Policies: Range Symmetry, Anchor trailing, Inventory, Operational.\n",
        "- Tools: Metrics, Stats, Models.\n",
        "\n",
        "Define fundamental areas of expertise/focus needed:\n",
        "\n",
        "- Management / Business logic expectations\n",
        "\t- Resources availability\n",
        "\t- time window\n",
        "- Engineering\n",
        "\n",
        "## Overlooked principles\n",
        "\n",
        "- Tick distance in OrderDriven CEX are post-defined by market demand, and although not by default or always present, they are always quotable (usable) at trader's will. In CL-AMM tick spaces are pre-defined, and done so by a protocol criteria based on volatility.\n"
      ],
      "metadata": {
        "id": "zhjXBTlIJo1X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e079uJ-LJuuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Expectations\n",
        "---"
      ],
      "metadata": {
        "id": "ZAFotJ0BJ18P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "70% of the effort should be towards :\n",
        "- An algo development platform (Codes, References, Hypothesis, Working group).\n",
        "- A deployment system with \"dev/staging/production\" levels of maturity.\n",
        "- A monitoring system to keep bounded costs (the resulting combination of PnL and Direct infrastructure costs).\n",
        "\n",
        "30% of the remaining should towards the development and continuous improvement of the capacity to conduct rapid iterations of trading hypothesis. Ideally, anyone in the company with enough time and skill/resources should be able to develop an idea, test it and present it to decision makers.\n",
        "\n",
        "The expected system's stability will be measured throughout 3 different aspects, each of which representing a different attribution of results from the company, from the least controlable to the almost fully controlable one:\n",
        "\n",
        "- Market metrics:\n",
        "\t- Existing Volume per LP.\n",
        "- Operations metrics\n",
        "\t- Computational Metrics\n",
        "\t- Networking Metrics\n",
        "\t- Uptime, Posted Liquidity.\n",
        "\t- From idea to deployment cycle\n",
        "- Performance metrics.\n",
        "\t- Quoted Volume per LP.\n",
        "\t- Risk adjusted Profit\n",
        "- Risk Metrics:\n",
        "\t- Adverse selection indicator (VPIN Model).\n",
        "\t- Token Inflow/Outflow DEX/CEX Monitoring.\n",
        "\t- Expected clusters of trading activity (Hawkes Model).\n",
        "\n"
      ],
      "metadata": {
        "id": "r5eeGLeqJ-RE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Roadmap\n",
        "---"
      ],
      "metadata": {
        "id": "wVoGw8nzKBtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 0 : Hypothesis\n",
        "\n",
        "- Duration: 3 days\n",
        "- Purpose: Acknowledge existing resources, requirements, and knowledge from other team members, industry content and Academic literature.\n",
        "- Tasks:\n",
        "\t- Benchmark definition (The cost of doing nothing, as a baseline).\n",
        "\t- Explore the state of the art (internally in company, industry content, and, academia).\n",
        "- Outcome:\n",
        "\t- Definition on the source for alpha: The unfair advantage we can have.\n",
        "\t- Notes on available resources and constrains: People, Tech, Knowledge, Time, Data, Infrastructure, Licenses, Tools.\n",
        "\n",
        "## Phase 1: PoC exploration\n",
        "\n",
        "- Duration: 2 weeks\n",
        "- Purpose: Test the most fundamental and risky assumptions in the Hypothesis.\n",
        "- Tasks:\n",
        "\t- build basic data acquisition layer (Later will become the Data-Infrastructure repo/project)\n",
        "\t- build basic data structures  (Later will become Data-Infrastructure repo/project)\n",
        "\t- build data pre-processing and EDA locally (Later will become model-amm repo/project)\n",
        "\t- Exploratory Data Analysis for Stylized Facts validations\n",
        "\t\t- For comparison purposes, chose 3 pairs that are very different according to a given dimension (tokenomics, purpose, liquidity profile ...).\n",
        "\t\t- Define, build and execute a basic Exploratory Data Analysis with the basic statistical tests (distributions, outliers, ranges)\n",
        "\t\t- Define a list of questions whose answer might be an stylized fact:\n",
        "\t\t\t- Is there an observable pattern for a particular metric ? (quoted volume across different hours of the day, intraday volatility clusters, spoof trading, pump and dump...)\n",
        "\t\t\t- Do the involved tokens have known restricted/calendarized monetary/minting policies for scheduling supply?\n",
        "\t\t\t- other similar questions and respective data-based explorations.\n",
        "- Outcome:\n",
        "\t- repos:\n",
        "\t\t- data-infrastructure: Data Acquisition codes\n",
        "\t\t- model-amm: EDA methods for Hypothesis Testing\n",
        "\t- presentation:\n",
        "\t\t- Present results and discus findings with the team.\n",
        "\n",
        "## Phase 2 : Alpha version\n",
        "\n",
        "- Duration: 6 weeks\n",
        "- Purpose: Build initial data-infrastructure, modeling, execution, monitoring functional layers to test altogether.\n",
        "- Tasks:\n",
        "\t- Data infrastructure:\n",
        "\t\t- SDK for basic operations with smart contract in Ekubo and Uniswap v3\n",
        "\t\t- Data Structures (Standardize naming, units, etc, across venues),\n",
        "\t\t- Data Pipeline:\tSerialization/Deserialization processes, pre-processing for standardization)\n",
        "\t\t- Data Storage: Partitioning schemas, Database definition/access.\n",
        "\t\t- Data Monitoring: Data completeness metric definition (expected amount of data or activity per unit of time.\n",
        "\t- Modeling:\n",
        "\t\t- Forecast Boundaries:\n",
        "\t\t\t- target variable:\n",
        "\t\t\t- lower-bound price + upper-bound price + bounded-volume.\n",
        "\t\t- Option B:\n",
        "\t\t\t- forecast volatility\n",
        "\t\t- price chase\n",
        "\t\t- rebalance\n",
        "\t\t- Adverse selection indicator (VPIN Model).\n",
        "\t\t- Token Inflow/Outflow DEX/CEX Monitoring.\n",
        "\t\t- Expected clusters of trading activity (Hawkes Model).\n",
        "\n",
        "- Basic position management (mint, burn, collect fees)\n",
        "- Price oracle integration with redundancy and validation\n",
        "- Gas estimation and optimization framework\n",
        "## Phase 1: Data-Infrastructure\n",
        "\n",
        "- Purpose: Build, test and present the fundamental definitions and methods for data acquisition, pre-processing and storing.\n",
        "- Paradigm: Monolithic\n",
        "- Stack: Terraform + Shell + Docker + SQL\n",
        "- Initial global data model:\n",
        "\t- Standardize naming, units for symbols, CEX/DEX, chains, transactions.\n",
        "\t- Data structures: Aware of Serialization and Partition needs.\n",
        "\t- Base methods: for HTTP, WSS, gRPC, Unstructured/Raw, Data Systems.\n",
        "- Initial Source Mapping:\n",
        "\t- Oracle categorization/exploration/prioritization based on Hypothesis.\n",
        "- Monitoring\n",
        "\t- MEV monitoring HoneyPot\n",
        "\n",
        "## Data Layer (Off-chain).\n",
        "\n",
        "- Create the global data model:\n",
        "\t- Standardize naming, units for symbols, CEX/DEX, chains, transactions.\n",
        "\t- Data structures: Aware of Serialization and Partition needs.\n",
        "\t- Base methods: for HTTP, WSS, gRPC, Unstructured/Raw.\n",
        "- Source Catalog:\n",
        "\t- Oracle categorization/exploration\n",
        "\t- Prioritization based on hypothesis\n",
        "\t- Access/resource/monitoring allocation based on purpose\n",
        "\n",
        "- e.g. Selected pair from Hypothesis dictates data pipeline sourcing priority, not only price and volume, also any other tokenomics-related, category-related, usage-related.\n",
        "- Build the Global Price Model (Oracle integrations with redundant price feeds)\n",
        "\n",
        "## Compute Layer (Off-chain)\n",
        "\n",
        "- Local Development\n",
        "\t- Preferably: Unix-like (or linux distro), local repo, execution on docker images, local stack, env variables)\n",
        "- Data Worker\n",
        "\t- Docker, Throughput or i/o optimized image, Serializer/Deserializer, DB Connectivity, Pre-processing.\n",
        "- Compute Worker\n",
        "\t- Docker, Compute optimized image\n",
        "- Execution Worker\n",
        "\t- private mempool integration for MEV protection.\n",
        "\n",
        "## Infrastructure\n",
        "\n",
        "- Cloud Development Setup.\n",
        "- Storage model.\n",
        "- Data Acquisition Workers.\n",
        "- Data Processing Workers.\n",
        "\n",
        "Later stages depending on success and lessons learned from the previous ones:\n",
        "- Advanced Modeling\n",
        "- Model Calibration\n",
        "- Model efficacy and Resources efficiency\n",
        "\n"
      ],
      "metadata": {
        "id": "4K1I_Ug4KByB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prioritization\n",
        "---"
      ],
      "metadata": {
        "id": "BZJkOJSXKB0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impact dimensions:\n",
        "\n",
        "- TS: Time spent\n",
        "- FR: Financial risk\n",
        "- FP: Financial profit\n",
        "- TR: Technology risk\n",
        "- OR: Operational risk\n",
        "\n",
        "Effort scale:\n",
        "\n",
        "- Hours Spent Developing\n",
        "- Hours Spent Maintaining\n",
        "\n",
        "\n",
        "## Alpha Version Features\n",
        "\n",
        "Purpose: Start the iteration cycle with focus on simplicity, monitoring capacity, lower financial impact.\n",
        "\n",
        "- **Price-Range**:\n",
        "\t- Determination: Lower and upper bound prices determination based on %bps from TOB.\n",
        "\t- Management: Rebalancing every hour (For monitoring purposes as well)\n",
        "\t- High priority for time: Main source of time spent (monitoring, tooling, simplistic models)\n",
        "\t- Lower Financial Risk at the expense of lowering financial profit\n",
        "\t- Do not avoid but identify well technology and operational risk\n",
        "- **Posted-Volume**:\n",
        "\t- Determination: The intentional volume or amount to post within the price boundary.\n",
        "\t- Low priority: The upper bound of supported posted volume will later be optimized.\n",
        "\t- This lowers financial risk, and lowers impact of technology and operational risk as well.\n",
        "- **MEV Protection**: Flashbots integration for private transaction submission.\n",
        "\t- Medium priority: Meta data around execution context is important but only after price-range static and price-chase are defined and tested.\n",
        "- **Protocol Support**: Initial focus on Uniswap V3\n",
        "\t- High priority since it potential has faster development cycle.\n",
        "\t- This lowers financial risk, and lowers impact of technology and operational risk as well.\n",
        "- **Capital Management**: Basic fee collection\n",
        "\t- Lower priority on auto-compounding.\n",
        "\n",
        "## Beta Version Features\n",
        "\n",
        "Purpose: Enhance iteration cycle by focusing on pattern finding and value extracting, monitoring capacity enhanced a bit towards performance attribution, noticeable up-side financial impact exposure.\n",
        "\n",
        "- **Advanced Rebalancing Modes**: Price-chase and volatility-adaptive strategies\n",
        "- **Ekubo Integration**: Cross-protocol optimization and comparison\n",
        "- **Auto-compounding**: Automated fee reinvestment with gas optimization\n",
        "- **Multi-position Management**: Risk distribution across multiple ranges\n",
        "\n",
        "## Future Iterations\n",
        "\n",
        "Purpose: Either breadth expansion towards other venues for the same token-class, or, double-down into more value extraction in the same set of LPs or token pairs.\n",
        "\n",
        "- **Cross-protocol Arbitrage**: Automated opportunity detection and execution\n",
        "- **ML-based Optimization**: Reinforcement learning for strategy parameter tuning\n",
        "- **Flash Loan Integration**: Capital efficiency improvements through leveraged positions\n",
        "- **Cross-chain Deployment**: Extension to L2s and alternative chains\n"
      ],
      "metadata": {
        "id": "Y7Yh9tjiKB2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Risks and Mitigation\n",
        "---"
      ],
      "metadata": {
        "id": "Rik8RyUTKB5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "| Risk Category                      | Severity | Likelihood | Mitigation Strategy                                                                                               |\n",
        "| ---------------------------------- | -------- | ---------- | ----------------------------------------------------------------------------------------------------------------- |\n",
        "| **MEV Extraction**                 | High     | High       | - Private mempool integration<br>- Transaction timing optimization<br>- Slippage bounds enforcement               |\n",
        "| **Oracle Manipulation**            | Critical | Low        | - Multi-oracle architecture.<br>- Stabilized Cross-reference Pricing.<br>- Circuit breakers for extreme movements |\n",
        "| **Gas Cost Spikes**                | Medium   | High       | - Dynamic gas pricing<br>- Profitability checks before rebalancing                                                |\n",
        "| **Impermanent Loss During Trends** | High     | Medium     | - Trend detection algorithms<br>- Asymmetric range adjustment<br>- Position hedging options                       |\n",
        "| **Protocol Changes**               | Medium   | Medium     | - Version detection<br>- Graceful degradation<br>- Rapid deployment pipelines for updates                         |\n",
        "| **Liquidity Fragmentation**        | Medium   | Low        | - Token Flow Tracking<br>- Minimum liquidity thresholds<br>- Alternative venue fallbacks                          |\n",
        "| **Regulatory Changes**             | High     | Low        | - Compliance monitoring<br>- Jurisdiction flexibility, operational transparency features                          |\n",
        "\n",
        "## MEV Extraction\n",
        "\n",
        "- **Private Mempool:** Use Flashbots, CoW Swap, Eden Network, or comparable/similar service as a \"private mempool\" during execution phase.\n",
        "- **Record MEV events:** Keep record on identified, and even suspected, MEV events. Use it as a record of \"Hot time-windows\" for execution.\n",
        "- **Execution Context:** Record metadata from an executed swap, or SDK operation, should include a \"surrounding measure\" to capture activity before, during, and after execution, for post-trade analysis.\n",
        "- **Execution Atomicity:** of intentions should be atomic in nature, all-or-nothing, to add extra protection and enforcement of bounds of allowed slippage.\n",
        "\n",
        "## Oracle manipulation\n",
        "\n",
        "- **Multi-oracle utilization:** To build an Stabilized Cross-Referenced Price using the median of the weighted price from sources from at least 2 DEX and 2 CEX.\n",
        "- **Circuit breaker:** Establish boundaries of volume to trade whenever a \"Hot time-window\" is occurring or has historically occurred.\n",
        "\n",
        "## Gas costs\n",
        "\n",
        "**Dynamic Gas Pricing Model:**\n",
        "- option 1: Martingale model as benchmark (what was the previous price, is expected to be the next price).\n",
        "- option 2: Regression model: Non-linear features with a Linear Model with Regularization:\n",
        "\n",
        "**Avoid  NFT-Minted Position:**\n",
        "The V3 SDK excels at off-chain position mathematics, providing precise calculations without blockchain interaction: [Uniswap v3 Docs - position-data](https://docs.uniswap.org/sdk/v3/guides/liquidity/position-data)\n",
        "\n",
        "**Profitability Check:**\n",
        "- Expected PnL should include the estimated boundaries for gas price + slippage.\n",
        "\n",
        "## Impermanent Loss Protection\n",
        "\n",
        "- **Adverse Selection Model:** Volumen-Synchronized Probability of Informed Trading (VPIN), volume-based detection of liquidity risk and trade flow toxicity.\n",
        "- **Asymmetric range adjustment:** According to the model\n",
        "\n",
        "## Protocol Changes\n",
        "\n",
        "- **Track technology risk:** SDK / Protocol uptime and fundamental changes detection.\n",
        "\n",
        "## Liquidity Fragmentation\n",
        "\n",
        "- **Token Flow Tracking:** Inflow/Outflow monitoring through identified active wallets interacting with the protocol and particular LPs.\n",
        "- **Alternative venue fallbacks**: List of alternative venues for position off-loading.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ElJpl4YmKB7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Technical Design\n",
        "---"
      ],
      "metadata": {
        "id": "Yw4ARS1_KB-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uniswap V3 Integration\n",
        "\n",
        "The Uniswap V3 ecosystem provides comprehensive tooling for off-chain automation:[](https://github.com/Aperture-Finance/uniswap-v3-automation-sdk)\n",
        "\n",
        "- **Position Management**: Full capacity which includes minting and burning a position, also fee collection.\n",
        "- **Quote Generation**: Real-time price impact calculation and slippage estimation, which is very convenient for a PoC and the Beta version, further versions should include an enhanced Optimal Execution based on Price Impact as well.\n",
        "- **Transaction Building**: Automated transaction construction with multi-hop routing optimization.  \n",
        "- **Analytics Integration**: Historical performance data\n",
        "\n",
        "**NFT minting can be completely avoided** through direct pool interaction\n",
        "\n",
        "## Ekubo Protocol Integration\n",
        "\n",
        "Ekubo's singleton architecture is specifically designed for external integrations: [Ekubo Docs](https://docs.ekubo.org/integration-guides/reference/ekubo-api)\n",
        "\n",
        "- **Extensions Framework**: Custom logic insertion at pool lifecycle events without core contract modification\n",
        "- **API-First Design**: REST API endpoints so is very convenient.\n",
        "- **Real-time Data Streams**: WSS connections with sub-second market data updates.\n",
        "- **Cross-Chain Abstraction**: Unified interface across Starknet and Ethereum for standard data structure and deployment definition.\n",
        "\n",
        "\n",
        "## Data-Infrastructure\n",
        "\n",
        "### Adverse Selection & Price-Range-Volume Chaser Model (mermaid)\n",
        "```mermaid\n",
        "sequenceDiagram\n",
        "autonumber\n",
        "\n",
        "participant Data-processing as Data-Processing\n",
        "participant DL as Data Lake\n",
        "participant Report-API as Protocol-SDK\n",
        "participant FE as Features Engine\n",
        "participant DW as Data Warehouse\n",
        "participant IE as Inference Engine\n",
        "\n",
        "Note over Report-API : START\n",
        "Note over Report-API : Event & Push to Topic <br/> [New forecast requested]\n",
        "Report-API ->> Data-processing :\n",
        "Note over Data-processing: Pull from Topic <br/> [New forecast requested]\n",
        "\n",
        "par forecast Data Generation\n",
        "\tData-processing --> Data-processing: Parse and validate\n",
        "\tData-processing -->> DL: Insert forecast Data\n",
        "\tDL -->> Data-processing: Successful Insert forecast Data\n",
        "end\n",
        "\n",
        "Note over Data-processing: Event & Push to Topic <br/> [forecast Data Ready]\n",
        "\n",
        "Note over FE: Pull from Topic <br/> [forecast Data Ready]\n",
        "par Feature Data Generation\n",
        "\tFE -->> DL: Fetch data\n",
        "\tFE -->> FE: Compute Features Data\n",
        "\tFE -->> DW: Insert Features Data\n",
        "\tDW -->> FE: Sucessful Insert Feature Data\n",
        "end\n",
        "Note over FE: Event & Push to Topic <br/> [Features Data Ready]\n",
        "\n",
        "Note over IE: Pull from Topic <br/> [Features Data Ready]\n",
        "par Inference Data Generation\n",
        "\tIE -->> DW: Fetch Model\n",
        "\tIE -->> DW: Fetch features\n",
        "\tIE --> IE: Model Inference\n",
        "\tIE -->> DW: Insert results\n",
        "\tDW -->> IE: Sucessful Insert Inferece Data\n",
        "end\n",
        "Note over IE: Event & Push to Topic <br/> [Inferece Data Ready]\n",
        "\n",
        "Note over Report-API: Pull from Topic <br/> [Inferece Data Ready]\n",
        "Report-API ->> DW: Fetch forecast\n",
        "Note over Report-API : FINISH\n",
        "```\n",
        "\n",
        "## Software Design Paradigm\n",
        "\n",
        "- Paradigm: Event-Driven\n",
        "- Taxonomy: Many-to-Many\n",
        "\n",
        "## Events\n",
        "\n",
        "### Main Functionality\n",
        "\n",
        "- **forecast_request**:\n",
        "    - **pf_forecast**: The request to produce the forecast for vpin, in this case by **SDK**.\n",
        "    - **pm_forecast**: The request to produce the forecast for price-range-chaser, in this case by **SDK**.\n",
        "- **forecast_data**:\n",
        "    - **generation_ok**: a stafisfactory data internal generation and/or external retrieval, in this case by **Data-processing**.\n",
        "    - **insertion_ok**: a satisfactory response gathered by the Process, in this case **Data-processing**.\n",
        "    - **existence_ok**: existence of the full and correct data by the DB, in this case **Data-Lake**.\n",
        "- **features_data**:\n",
        "    - **generation_ok**: a stafisfactory data internal generation, in this case by **Features-Engine**.\n",
        "    - **insertion_ok**: a satisfactory response gathered by the Process, in this case **Features-Engine**.\n",
        "    - **existence_ok**: existence of the full and correct data by the DB, in this case **Data-Warehouse**.\n",
        "- **inference_data**:\n",
        "    - **generation_ok**: a stafisfactory data internal generation, in this case by **Inference-Engine**.\n",
        "    - **insertion_ok**: a satisfactory response gathered by the Process, in this case **Inference-Engine**.\n",
        "    - **existence_ok**: existence of the full and correct data by the DB, in this case **Data-Warehouse**.\n",
        "\n",
        "### Logs and Monitoring\n",
        "\n",
        "- **log**:\n",
        "    - **DEBUG**: Free to use for development purposes.\n",
        "    - **INFO**: Constant info for validation/branching/structuring data sets.\n",
        "    - **WARNING**: A non-critical error.\n",
        "    - **SYSTEM_ERROR**: A systems error.\n",
        "    - **PROCESS_ERROR**: A modeling process error.\n",
        "    - **CRITICAL**: A unavoidable and urgent error to be fixed.\n",
        "\n",
        "## Events schemas\n",
        "\n",
        "- **Name**: {forecast_request, forecast_data, features_data, inference_data}.\n",
        "- **Payload**: {pf_forecast, pm_forecast, generation_ok, insertion_ok, existence_ok}\n",
        "\n",
        "## Routings\n",
        "\n",
        "- topic for forecast : **topic_forecast_events**\n",
        "- topic for logs : **topic_forecast_logs**\n",
        "\n",
        "## Ancillary code\n",
        "\n",
        "- **topic_publish.py** : A script to manually publish a message into an existing Pub/Sub topic.\n",
        "- **data_io.py** : A script to read/write data from and into both the Data Lake and the Data Warehouse.\n",
        "- **synthetic_data.py** : A script to create random content that follows the correct expected schema (both for the DL and DW).\n",
        "- **data_catalog.json** / **features_catalog.json** / **models_catalgo.json** : Schemas for each case\n",
        "\n",
        "## Error Handling\n",
        "\n",
        "### Input Data Stage\n",
        "\n",
        "- **SDK** fails to push to forecast topic the new_report message:\n",
        "    - Dead letter Queue : Do a 10x re-try cycle.\n",
        "    - Alternative: Run a manual script to push to topic.\n",
        "- **Data-processing** fails to pull from the forecast topic the new_report message:\n",
        "    - Do a 10x re-try cycle.\n",
        "    - Alternative: Use a script to manually trigger process::{forecast Data Generation}\n",
        "\n",
        "- **Data-processing** fails to parse and validate forecast_data:\n",
        "    - Use a script to manually create data.\n",
        "- **Data-processing** fails to insert forecast_data fully or partially into Data Lake:\n",
        "    - Do a 3x re-try cycle\n",
        "    - Alternative: Use a script to manually insert data into Data Lake.\n",
        "- **Data-processing** fails to push to forecast topic the forecast_data message:\n",
        "    - Dead letter queue: Do a 10x re-try cycle.\n",
        "    - Alternative: Run a manual script to push to topic.\n",
        "\n",
        "###  Feature Stage\n",
        "\n",
        "- **FEATURES ENGINE** fails to pull from forecast topic the forecast_data message:\n",
        "    - Do a 3x re-try cycle\n",
        "    - Alternative: Use a script to manually read the data from Data Lake.\n",
        "- **FEATURES ENGINE** fails to generate values:\n",
        "    - Alternative: Use a script to manually generate data.\n",
        "- **FEATURES ENGINE** fails to insert features_data:\n",
        "    - Do a 3x re-try cycle\n",
        "    - Alternative: Use a script to manually insert data into the Data Warehouse.\n",
        "- **FEATURES ENGINE** fails to push to forecast topic the features_data message:\n",
        "    - Dead letter Queue : Do a 10x re-try cycle.\n",
        "    - Alternative: Run a manual script to push to topic.\n",
        "\n",
        "### Inference Stage\n",
        "\n",
        "- **INFERENCE ENGINE** fails to pull from forecast topic the features_data message:\n",
        "    - Do a 3x re-try cycle\n",
        "    - Alternative: Use a script to manually read data from Data Warehouse.\n",
        "- **INFERENCE ENGINE** fails to generate values:\n",
        "    - Alternative: Use a script to manually generate data.\n",
        "- **INFERENCE ENGINE** fails to insert inference_data:\n",
        "    - Alternative: Use a script to manually insert data to Data Warehouse.\n",
        "- **INFERENCE ENGINE** fails to push to forecast topic the inference_data message:\n",
        "    - Dead letter Queue : Do a 10x re-try cycle.\n",
        "    - Alternative: Run a manual script to push to topic.\n",
        "\n",
        "### Final Data Stage\n",
        "\n",
        "- **SDK** fails to pull from forecast topic the inference_data message:\n",
        "    - Dead letter Queue : Do a 10x re-try cycle\n",
        "    - Alternative: Run a manual script to read from Data Warehouse.\n",
        "\n",
        "### Storage, retention, access\n",
        "\n",
        "- Inmediate: Entries in table of Logs and Metrics Database\n",
        "- Archive: Grouped in zipped file.\n",
        "\n",
        "### Monitoring and Alerts\n",
        "\n",
        "Grafana and its alerting systems (Slack/Email/SMS)\n",
        "\n",
        "- Dashboard for logs aggregation and visualization.\n",
        "- Alerting system for critical events.\n",
        "\n"
      ],
      "metadata": {
        "id": "pV0Fi8USKyZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UI & Design\n",
        "---"
      ],
      "metadata": {
        "id": "jdjFnMYaK7nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Streamlit** (Recommended for Alpha and Beta version)\n",
        "\n",
        "**Simplicity**: Streamlit excels for rapid prototyping with minimal code[](https://docs.kanaries.net/topics/Streamlit/streamlit-vs-dash)  \n",
        "**Learning Curve**: Nearly zero - uses pure Python syntax[](https://blog.streamlit.io/how-to-build-a-real-time-live-dashboard-with-streamlit/)  \n",
        "**Setup Time**: Dashboard in <50 lines of code\n",
        "\n",
        "**Strategy Overview Panel**:\n",
        "\n",
        "- Current positions across both protocols with P&L visualization    \n",
        "- Real-time fee earnings and Impermanent loss tracking\n",
        "- Performance metrics: APR, Sharpe ratio, max drawdown\n",
        "\n",
        "**Risk Monitoring Section**:\n",
        "\n",
        "- MEV attack detection alerts\n",
        "- Oracle deviation warnings\n",
        "- Gas cost impact analysis\n",
        "\n",
        "**Position Management Interface**:\n",
        "\n",
        "- Manual range adjustment with price impact simulation\n",
        "- Rebalancing trigger configuration (price thresholds, time intervals)\n",
        "- Emergency position closure controls\n",
        "\n",
        "**Configuration Visualization Settings**:\n",
        "\n",
        "- Slippage tolerance adjustment (0.1% - 2% range)\n",
        "- MEV protection preferences (speed vs. protection trade-off)\n",
        "- Capital allocation limits and position sizing rules"
      ],
      "metadata": {
        "id": "6akcr6hDK9n7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing & Validation\n",
        "---"
      ],
      "metadata": {
        "id": "ADOkhmX2LBrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Strategy Correctness Validation\n",
        "\n",
        "**Economic Model Validation**: Mathematical verification of fee calculation logic, impermanent loss computation. This includes edge case testing for extreme market conditions.\n",
        "\n",
        "**Protocol Integration Testing**: Exhaustive testing of smart contract interactions with both Ekubo and Uniswap v3 protocols. Tests cover normal operations, error conditions.\n",
        "\n"
      ],
      "metadata": {
        "id": "uwvz4tfcLEBk"
      }
    }
  ]
}